---
title: "Mini-Project #04: Just the Fact(-Check)s, Ma’am!"
author: "Nusrat Akter"
date: "`r Sys.Date()`"
format: 
  html: 
    theme: journal
    toc: true
    toc-depth: 3
    code-fold: true
    code-summary: "Show The Code"
    embed-resources: true
editor: visual
execute: 
  warning: false
  message: false
  echo: true
  cache: false
---

::: {style="text-align: left;"}
<img src="breakingnews.gif" width="670" style="border: 4px solid #000; border-radius: 10px;"/>
:::

# **What Is The Mission?**

This project looks at the controversy around President Trump firing BLS Commissioner Dr. Erika McEntarfer in August 2025. R and web scraping were used to examine patterns in the Monthly Current Employment Statistics, the jobs numbers that everyone watches closely. By pulling and analyzing revision data from the BLS website, I investigated whether recent revisions actually show anything unusual that might justify the firing, or if they're just normal statistical adjustments like the BLS says. I combined web scraping, data cleaning, statistical testing, and visualizations to see what the data really showed about one of the most important economic indicators in the country.

# **Data Acquisition**

::: callout-note
This project uses two CES data sources: **the final seasonally adjusted non-farm payroll employment levels and the month-to-month revisions to those levels**. We focus on total non-farm payrolls because it is the most widely discussed CES measure, especially in political and economic debates.
:::

# **Task 1: Download CES Total Nonfarm Payroll**

```{r}
#| echo: true
#| message: false
#| warning: false
#| codefold: true

library(httr2)
library(rvest)
library(dplyr)
library(tidyr)
library(stringr)
library(lubridate)
library(purrr)

# if cached file exists, load instead of scraping
if (file.exists("df_ces_levels.rds")) {

  df <- readRDS("df_ces_levels.rds")

} else {

  # request data
  resp <- request("https://data.bls.gov/pdq/SurveyOutputServlet") %>%
    req_method("POST") %>%
    req_body_form(
      request_action = "get_data",
      reformat = "true",
      from_results_page = "true",
      from_year = "1979",
      to_year = "2025",
      initial_request = "false",
      data_tool = "surveymost",
      series_id = "CES0000000001",
      original_annualAveragesRequested = "false"
    ) %>%
    req_perform()

  # extract large monthly table
  tbl <- resp_body_html(resp) %>%
    html_elements("table") %>%
    map(~ html_table(.x, fill = TRUE)) %>%
    keep(~ ncol(.x) > 5) %>%
    first()

  # clean
  df <- tbl %>%
    mutate(Year = as.integer(Year)) %>%
    pivot_longer(
      cols = -Year,
      names_to = "month",
      values_to = "level"
    ) %>%
    mutate(
      month = str_sub(month, 1, 3),
      date  = ym(paste(Year, month)),
      level = as.numeric(str_replace(level, ",", ""))
    ) %>%
    drop_na(date, level) %>%
    arrange(date) %>%
    select(date, level)

  # save file
  saveRDS(df, "df_ces_levels.rds")
}
```

::: callout-note
This code retrieves the **official CES employment levels** from the BLS website, either by loading a previously saved data set or by scraping the data if no cached file exists. When scraping, it sends a POST request to the BLS PDQ system, extracts the large monthly data table, reshapes it into tidy format, and converts the year–month fields into a proper date variable. Finally, it saves the cleaned data set **(df_ces_levels.rds)** so future runs won’t need to download the data again.
:::

# **Task 2: Download CES Revisions Tables**

```{r}
#| echo: true
#| message: false
#| warning: false
#| results: "hide"


library(httr2)
library(rvest)
library(dplyr)
library(purrr)
library(stringr)
library(lubridate)
library(tibble)

# if cached file exists, load instead of scraping 
if (file.exists("df_ces_revisions.rds")) {

  df_revisions <- readRDS("df_ces_revisions.rds")

} else {

  # scrape the BLS revision page
  resp <- request("https://www.bls.gov/web/empsit/cesnaicsrev.htm") %>%
    req_headers(
      "user-agent" = "Mozilla/5.0",
      "accept" = "text/html",
      "accept-language" = "en-US,en;q=0.5",
      "cache-control" = "no-cache"
    ) %>%
    req_perform()

  html <- resp_body_html(resp)

  # extract
  extract_year <- function(year, html) {

    tbl_node <- html %>% html_element(paste0("#", year))

    if (inherits(tbl_node, "xml_missing")) {
      return(tibble(
        Date = as.Date(character()),
        Original = numeric(),
        Final = numeric(),
        Revision = numeric()
      ))
    }

    tbl <- tbl_node %>%
      html_element("tbody") %>%
      html_table(fill = TRUE, header = FALSE) %>%
      slice(1:12) %>%
      select(month = 1, Original = 3, Final = 5) %>%
      mutate(
        Original = as.numeric(gsub("[^0-9-]", "", Original)),
        Final    = as.numeric(gsub("[^0-9-]", "", Final)),
        Date     = ym(paste(year, month)),
        Revision = Final - Original
      ) %>%
      select(Date, Original, Final, Revision)

    tbl
  }

  # get the available years provided
  available_years <- html %>%
    html_elements("table") %>%
    html_attr("id") %>%
    suppressWarnings(as.numeric()) %>%
    na.omit() %>%
    sort()


  df_revisions <- map_df(available_years, extract_year, html = html)

  # fix names so it joins with df
  df_revisions <- df_revisions %>% rename(date = Date)

  # cache for future runs
  saveRDS(df_revisions, "df_ces_revisions.rds")
}
```

::: callout-note
This code loads previously saved CES revision data if it exists; otherwise, it scrapes the BLS revisions webpage, extracts each year’s monthly revision table, cleans it into a usable format, and saves the result for future use.
:::

# **Task 3: Data Exploration And Visualization**

## Table Joining

```{r}
#| echo: true
#| message: false
#| warning: false
#| results: "hide"

library(dplyr)
library(lubridate)

df_joined <- df %>%
left_join(df_revisions, by = "date") %>%
arrange(date)

```

::: callout-note
This code **joins the CES employment data with the revision data** using the shared date column and then sorts everything by time. The result is a single data set that includes both the reported level and its revision for each month. This combined table is what the later analysis uses.
:::

## Largest Positive And Negative Revisions In CES History

```{r}
#| echo: true
#| message: false
#| warning: false
#| codefold: true

library(dplyr)
library(knitr)
library(kableExtra)

# compute largest positive & negative revisions
largest_pos  <- df_joined %>% slice_max(Revision, n = 1)
largest_neg  <- df_joined %>% slice_min(Revision, n = 1)

# build table
largest_revisions <- bind_rows(
  largest_pos %>% mutate(Type = "Largest Positive Revision"),
  largest_neg %>% mutate(Type = "Largest Negative Revision")
) %>%
  select(Type, Date = date, Original, Final, Revision)

largest_revisions %>%
  kable(
    caption = "Largest Positive and Negative CES Revisions",
    format = "html",
    col.names = c("Type", "Date", "Original", "Final", "Revision"),
    align = c("c","c","c","c","c")
  ) %>%
  kable_styling(
    full_width = FALSE,
    bootstrap_options = c("striped", "hover", "condensed")
  ) %>%
  row_spec(0, bold = TRUE)
```

::: callout-tip
## What Does This Show?

The largest positive CES revision happened in **November 1st, 2021**, where the estimate rose from **`r largest_pos$Original`** to **`r largest_pos$Final`**, a jump of **`r largest_pos$Revision` jobs**. The largest negative revision occurred in March 1st, 2020, when the estimate dropped from **`r largest_neg$Original`** to **`r largest_neg$Final`**, a decrease of **`r largest_neg$Revision` jobs**.
:::

## Fraction Of CES Revisions That Are Positive

```{r}
#| echo: true
#| message: false
#| warning: false
#| codefold: true

library(dplyr)
library(lubridate)
library(scales)
library(knitr)
library(kableExtra)

# compute revision direction by decade
decade_summary <- df_joined %>%
  mutate(decade = floor(year(date) / 10) * 10) %>%
  group_by(decade) %>%
  summarise(
    Observations = n(),
    Positive = mean(Revision > 0),
    Negative = mean(Revision < 0),
    Zero = mean(Revision == 0)
  ) %>%
  mutate(
    Positive = percent(Positive),
    Negative = percent(Negative),
    Zero = percent(Zero)
  )

# formatt table
decade_summary %>%
  kable(
    caption = "Fraction of CES Revisions by Decade",
    format = "html",
    col.names = c("Decade", "Observations", "Positive", "Negative", "Zero"),
    align = c("c", "c", "c", "c", "c")  
  ) %>%
  kable_styling(
    full_width = FALSE,
    bootstrap_options = c("striped", "hover", "condensed")
  ) %>%
  row_spec(0, bold = TRUE)
```

::: callout-tip
## What Does This Show?

Across decades, positive revisions occur slightly more often than negative ones. For example, in the **1990s**, about **`r decade_summary$Positive[decade_summary$decade == 1990]`** of revisions were **positive**, and in the **2010s** the share was **`r decade_summary$Positive[decade_summary$decade == 2010]`**. By contrast, the **1970s** had only **`r decade_summary$Positive[decade_summary$decade == 1970]` positive** revisions, and the **2020s** show a similar pattern with **`r decade_summary$Positive[decade_summary$decade == 2020]` positive**. Zero revisions remain extremely rare, staying at or below **`r decade_summary$Zero[2]`** across all decades.
:::

## How Revision Magnitudes Changed Over Time

```{r}
#| echo: true
#| message: false
#| warning: false

library(dplyr)
library(ggplot2)
library(lubridate)

df_decade_plot <- df_joined %>%
  mutate(decade = floor(year(date) / 10) * 10) %>%
  filter(decade >= 1970) %>%
  group_by(decade) %>%
  summarise(avg_abs_revision = mean(abs(Revision)))

# create plot
ggplot(df_decade_plot, aes(x = factor(decade), y = avg_abs_revision)) +
  geom_col(fill = "#2C7BB6", color = "black", linewidth = 0.4) +
  labs(
    title = "Average Absolute CES Revision by Decade",
    x = "Decade",
    y = "Avg Absolute Revision (Jobs)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(size = 20, face = "bold", hjust = 0.5),
    axis.title.x = element_text(size = 14, face = "bold"),
    axis.title.y = element_text(size = 14, face = "bold"),
    axis.text = element_text(size = 12),
    panel.grid.minor = element_blank()
  )
```

::: callout-tip
## What Does Figure 1 Show?

The average absolute CES revision was highest in the **1970s**, at **`r df_decade_plot$avg_abs_revision[df_decade_plot$decade == 1970]` jobs**. Revision magnitudes declined in subsequent decades, falling to **`r df_decade_plot$avg_abs_revision[df_decade_plot$decade == 2000]`** in the **2000s** and **`r df_decade_plot$avg_abs_revision[df_decade_plot$decade == 2010]`** in the **2010s**. This pattern indicates that revisions have grown smaller and more stable over time, reflecting improvements in CES measurement practices.
:::

## Revisions As % Of Overall CES Level

```{r}
#| echo: true
#| message: false
#| warning: false
#| codefold: true

library(dplyr)
library(lubridate)

revision_pct_stats <- df_joined %>%
  mutate(revision_pct = Revision / level * 100) %>%
  summarise(
    avg_pct_revision = mean(revision_pct, na.rm = TRUE),
    max_pct_revision = max(revision_pct, na.rm = TRUE),
    min_pct_revision = min(revision_pct, na.rm = TRUE)
  )
```

```{r}
#| echo: true
#| message: false
#| warning: false
#| codefold: true

library(dplyr)
library(ggplot2)
library(lubridate)

# create percent-revision

df_pct <- df_joined %>%
    mutate(revision_pct = (Revision / level) * 100)

# create plot using code chunk above

ggplot(df_pct, aes(x = date, y = revision_pct)) +
    geom_line(color = "steelblue", linewidth = 0.8, alpha = 0.9) +
    geom_smooth(
        method = "loess",
        color = "#D95F02",
        se = FALSE,
        linewidth = 1.2,
        span = 0.2
    ) +
    labs(
        title = "CES Revisions % of Overall CES Level (1979–2025)",
        x = "Date",
        y = "Revision (% of Level)"
    ) +
    theme_minimal(base_size = 14) +
    theme(
        plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
        axis.title = element_text(face = "bold"),
        panel.grid.minor = element_blank()
    )
```

::: callout-tip
## What Does Figure 2 Show?

Overall, CES revisions are extremely small when scaled to the total employment level. On average, revisions are only **`r round(revision_pct_stats$avg_pct_revision, 3)`%** of the CES level, with the **largest** percent revision at **`r round(revision_pct_stats$max_pct_revision, 3)`%** and the **smallest** at **`r round(revision_pct_stats$min_pct_revision, 3)`%**. The plot shows that the percent revisions stay very close to zero throughout the entire period, meaning that, even when the job-level changes look large, the revisions are tiny relative to total U.S. employment.
:::

## Months With Systematically Larger/Smaller CES Revisions

```{r}
#| echo: true
#| message: false
#| warning: false
#| codefold: true

library(dplyr)
library(ggplot2)
library(lubridate)

# prepare month name variable

df_month_plot <- df_joined %>%
    mutate(month_name = month(date, label = TRUE))

# create box plot

ggplot(df_month_plot, aes(x = month_name, y = Revision)) +
    geom_boxplot(fill = "#C3A6FF", color = "black", outlier.color = "black") +
    labs(
        title = "Distribution of CES Revisions by Month",
        x = "Month",
        y = "Revision (Jobs)"
    ) +
    theme_minimal(base_size = 14) +
    theme(
        plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
        axis.title = element_text(face = "bold")
    )
```

::: callout-tip
## What Does Figure 3 Show?

The box plot shows clear monthly patterns in revision size. **January** and **February** have **larger and more variable revisions**, while mid-year months like **June** through **August** show much **smaller** andmore **stable** revisions. This means revision size changes across the year and is higher during months when seasonal adjustments and benchmarking updates occur.
:::

## Average CES Revision (Absolute And Percent)

```{r}
#| echo: true
#| message: false
#| warning: false
#| codefold: true

library(dplyr)
library(lubridate)

rev_summary <- df_joined %>%
  mutate(
    abs_revision = abs(Revision),
    revision_pct = Revision / level * 100
  ) %>%
  summarise(
    avg_abs_revision = mean(abs_revision),
    avg_pct_revision = mean(revision_pct)
  )
```

```{r}
#| echo: true
#| message: false
#| warning: false
#| codefold: true

library(dplyr)
library(ggplot2)

# create plot using code chunk above
ggplot(df_joined, aes(x = Revision)) +
  geom_histogram(
    aes(y = after_stat(density)),
    bins = 40,
    fill = "#7DB4E6",
    color = "white",
    alpha = 0.8
  ) +
  geom_density(
    color = "#1F77B4",
    linewidth = 1.2
  ) +
  labs(
    title = "Distribution of CES Revisions",
    x = "Revision (Jobs)",
    y = "Density"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
    axis.title = element_text(face = "bold")
  )
```

::: callout-tip
## What Does Figure 4 Show?

CES revisions are usually very small. The average revision is about **62 jobs**, and the distribution plot shows most revisions sitting close to zero. In percent terms, revisions are only around **0.06%** of total employment, which is tiny relative to the overall CES level. Overall, revisions don’t meaningfully change the broader employment picture.
:::

# **Task 4: Statistical Inference**

## Is Mean CES Revision Different From 0?

```{r}
#| echo: true
#| message: false
#| warning: false
#| codefold: true

library(dplyr)
library(lubridate)
library(infer)
library(knitr)
library(kableExtra)

# test 1
obs_stat <- df_joined %>%
  specify(response = Revision) %>%
  hypothesize(null = "point", mu = 0) %>%
  calculate(stat = "t")

null_dist <- df_joined %>%
  specify(response = Revision) %>%
  hypothesize(null = "point", mu = 0) %>%
  generate(reps = 20000, type = "bootstrap") %>%
  calculate(stat = "t")

test1_p <- null_dist %>%
  get_p_value(
    obs_stat = obs_stat,
    direction = "two_sided"
  )

# p value
p_exp <- signif(test1_p$p_value, digits = 3)

test1_table <- tibble(
  `Observed t-statistic` = round(obs_stat$stat, 3),
  `P-value` = p_exp
)

test1_table %>%
  kable(
    caption = "Test 1: One-Sample T-Test For Mean CES Revision = 0",
    format = "html",
    align = "c"
  ) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")) %>%
  row_spec(0, bold = TRUE)
```

::: callout-tip
## What Does This Show?

The one-sample t-test shows that the mean CES revision is clearly different from zero. The observed t-statistic is **`r round(obs_stat$stat, 3)`**, and the bootstrap p-value is **`r round(test1_p$p_value, 4)`**, which is extremely small. This means a revision this far from zero would be very unlikely if the true mean revision were actually zero. Based on this result, we **reject the null hypothesis** and conclude that the average CES revision is not zero.
:::

## Compare Proportion of Negative Revisions Pre vs Post 2000

```{r}
#| echo: true
#| message: false
#| warning: false
#| codefold: true

library(dplyr)
library(lubridate)
library(infer)
library(knitr)
library(kableExtra)

# create and prepare the data for the test
df_test <- df_joined %>%
  mutate(
    period   = if_else(year(date) < 2000, "pre2000", "post2000"),
    negative = Revision < 0
  )

# proportion test
test2_result <- df_test %>%
  prop_test(
    negative ~ period,
    order = c("pre2000", "post2000"),
    alternative = "greater"
  )

# create a table for the results
test2_table <- tibble(
  `Test Statistic (z)` = round(test2_result$statistic, 3),
  `P-value` = round(test2_result$p_value, 5)
)

test2_table %>%
  kable(
    caption = "Test 2: Are Negative Revisions More Common After 2000?",
    format = "html",
    align = "c"
  ) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")) %>%
  row_spec(0, bold = TRUE)
```

::: callout-tip
## What Does This Show?

The proportion test compares how often CES revisions were negative before and after 2000. The estimated difference shows that negative revisions occur more frequently in the post-2000 period, and the test statistic from the proportional test is **`r round(test2_result$statistic, 3)`** with a p-value of **`r signif(test2_result$p_value, 4)`**. Because the p-value is very small, we **reject the null hypothesis** and conclude that negative revisions are significantly more common after 2000 than before.
:::

# **Task 5: Fact Checks Of Claims About BLS**

::: {style="text-align: left;"}
<img src="breakingnews2.gif" width="670" style="border: 4px solid #000; border-radius: 10px;"/>
:::

## Claim #1: *“During Obama’s Presidency, The BLS Job Numbers Were Constantly Revised Downward.”*

```{r}
#| echo: true
#| message: false
#| warning: false
#| results: "hide"

library(dplyr)
library(lubridate)
library(infer)



# filter obama-era data

obama_df <- df_joined %>%
filter(date >= ymd("2009-02-01"),
date <  ymd("2017-02-01"))


# one-sample t-test on revisions

obs_obama <- obama_df %>%
specify(response = Revision) %>%
hypothesize(null = "point", mu = 0) %>%       
calculate(stat = "t")

# bootstrap-based null distribution

null_obama <- obama_df %>%
specify(response = Revision) %>%
hypothesize(null = "point", mu = 0) %>%
generate(reps = 5000, type = "bootstrap") %>%
calculate(stat = "t")

# get p-value in left tail

pval_obama <- null_obama %>%
get_p_value(obs_obama, direction = "left")

pval_obama   


# summary stats table

obama_stats <- obama_df %>%
summarise(
mean_revision   = mean(Revision, na.rm = TRUE),
median_revision = median(Revision, na.rm = TRUE),
sd_revision     = sd(Revision, na.rm = TRUE),
prop_negative   = mean(Revision < 0),
min_revision    = min(Revision, na.rm = TRUE),
max_revision    = max(Revision, na.rm = TRUE),
n_months        = n()
)

obama_stats
```

::: callout-tip
## What Is Being Said?
This claim argues that CES first-release job counts during Barack Obama’s presidency (Feb 2009–Jan 2017) were systematically overstated and then routinely revised downward. The data, however, show the opposite.
:::

## Hypothesis Test

**I performed a one-sample t-test on the Obama-era CES revisions:**

-   *H₀: Mean revision = 0*

-   *H₁: Mean revision \< 0*

**The infer-based t-test yields:**

-   *P-value: 1.0*

*A p-value of 1.0 means the sample mean is actually above 0, and there is zero evidence of downward bias.*

## Numerical Statistics

-   *Mean revision: +20.8*

-   *Median revision: +19*

-   *Proportion negative: 0.333*

-   *Standard deviation: 41.8*

-   *Minimum revision: -73*

-   *Maximum revision: +124*

-   *Number of months: 96*

### **Interpretation:**

-   *positive on average*

-   *more often upward (67%) than downward (33%)*

-   *not large (SD ≈ 41 jobs)*

-   *not skewed negative*

## Visual Evidence

#### **Figure 1: “Average Absolute CES Revision by Decade”**

*Shows that the 2010s (Obama era) had **moderate, historically normal revision sizes**, lower than several earlier decades.*

#### **Figure 2: “CES Revisions as % of Overall CES Level (1979–2025)”**

*Shows that Obama revisions were **tiny relative to total CES employment**, almost always within **±0.25%**.*

*Both visuals clearly contradict the idea of persistent downward corrections.*

## Absolute Levels

*CES employment levels rose steadily after 2010. Upward movement in absolute levels supports the conclusion that the initial job numbers were not consistently **“too high”** or **“inflated.”***

## Politifact Rating: "PANTS ON FIRE"

-   *Obama revisions were positive, not negative.*

-   *Downward revisions occurred only 33% of the time.*

-   *No statistical, visual, or contextual evidence supports the claim.*

::: {style="text-align: left;"}
<img src="breakingnews3.gif" width="650" style="border: 4px solid #000; border-radius: 10px;"/>
:::

## CLAIM #2: *"Trump-era CES Job Numbers Were More Accurate (Smaller Revisions)"*

```{r}
#| echo: true
#| message: false
#| warning: false
#| results: "hide"


library(dplyr)
library(lubridate)
library(infer)


# obama vs. trump dataset with absolute revision

df_compare <- df_joined %>%
mutate(
pres = case_when(
date >= ymd("2009-02-01") & date < ymd("2017-02-01") ~ "Obama",
date >= ymd("2017-02-01") & date < ymd("2021-02-01") ~ "Trump",
TRUE ~ NA_character_
),
abs_rev = abs(Revision)
) %>%
filter(!is.na(pres))


# difference in means between trump & obama

obs_trump <- df_compare %>%
specify(abs_rev ~ pres) %>%
hypothesize(null = "independence") %>%
calculate(stat = "diff in means", order = c("Trump", "Obama"))



# null distribution

null_trump <- df_compare %>%
specify(abs_rev ~ pres) %>%
hypothesize(null = "independence") %>%
generate(reps = 5000, type = "permute") %>%
calculate(stat = "diff in means", order = c("Trump", "Obama"))



# 4. p-value to test if trump revisions are smaller

pval_trump <- null_trump %>%
get_p_value(obs_trump, direction = "less")

pval_trump


# stats table summary

compare_stats <- df_compare %>%
group_by(pres) %>%
summarise(
mean_abs_revision   = mean(abs_rev, na.rm = TRUE),
median_abs_revision = median(abs_rev, na.rm = TRUE),
sd_abs_revision     = sd(abs_rev, na.rm = TRUE),
pct_large           = mean(abs_rev > 50000),
n_months            = n()
)

compare_stats
```

::: callout-tip
## What Is Being Said?
This claim implies that CES first-release job numbers during Donald Trump’s presidency (Feb 2017–Jan 2021) had smaller revisions, indicating higher initial accuracy.
:::

## Hypothesis Test

**To test accuracy, I compare absolute revision magnitudes:**

-   *H₀: \|Revision\|Trump = \|Revision\|Obama*

-   *H₁: \|Revision\|Trump \< \|Revision\|Obama*

**The infer-based permutation test gives:**

-   *p-value: 0.971*

### **Interpretation:**

***A p-value of 0.971 means:***

-   *Trump revisions were **NOT** smaller*

-   *There is **no statistical evidence** of improved accuracy*

-   *If anything, the data lean in the opposite direction*

## Numerical Statistics

| President | Mean   | Median | SD      | \% \> 50k | n   |
|-----------|--------|--------|---------|-----------|-----|
| Obama     | 37.1   | *30.5* | 28.1    | *0%*      | 96  |
| Trump     | *58.8* | *25.5* | *104.1* | *0%*      | 50  |

### **Interpretation:**

-   ***Trump mean absolute revision = 58.8**, **much larger** than Obama’s 37.1*

-   *Trump’s SD = 104.1 (almost 4× Obama’s variability)*

-   *Trump’s revisions were **less stable**, **more volatile**, and **larger** on average*

## Visual Evidence

#### **Figure 4: “Distribution of CES Revisions (Histogram + Density)”**

*Shows Trump-era revisions fall in the **upper tail**, with more large values.*

#### **Figure 3: “Distribution of CES Revisions by Month (Boxplots)”**

*Shows revision variability is high all year and **does not shrink** under Trump.*

*Both plots show **no improvement** under Trump.*

## Absolute Levels

*CES employment levels collapsed in 2020 during COVID-19. Such extreme volatility naturally causes large revisions which are unrelated to administrative accuracy or BLS performance*

## Politifact Rating: "MOSTLY FALSE"

-   *Trump revisions were **not smaller***

-   *Trump revisions were **not more accurate***

-   *Trump revisions had **higher mean and higher variability***

-   *No statistical or visual evidence supports the claim*

### Sources

**Claim #1:**\
[Politifact – “Jack Welch says Obama manipulated jobs report”](https://www.politifact.com/factchecks/2012/oct/05/jack-welch/jack-welch-says-obama-manipulated-jobs-report/)

**Claim #2:**\
[Politifact – “Trump says his economic numbers were the best ever”](https://www.politifact.com/factchecks/2020/aug/07/donald-trump/trump-says-his-economic-numbers-were-best-ever/)
